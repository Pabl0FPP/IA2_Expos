{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/armandoordonez/GenAI/blob/main/Lab_2_fine_tune_generative_ai_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzpMK6XbV7aR",
    "tags": []
   },
   "source": [
    "# Fine-Tune un modelo de Gen AI Model para resúmenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObK2CXbTV7aT"
   },
   "source": [
    "En este cuaderno, se hará en fine-tune de un LLM existente de Hugging Face para mejorar el resumen de los diálogos. Utilizará el modelo [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5), que proporciona un modelo tuneado con instrucciones de alta calidad y puede resumir texto. Para mejorar las inferencias, se usará full fine-tuning y evaluará los resultados con métricas de ROUGE. Luego, se usará Parameter Efficient Fine-Tuning (PEFT), evaluará el modelo resultante y verá que los beneficios de PEFT superan las desventajas de rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PE1nZWSwV7aU"
   },
   "source": [
    "# Tabla de contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuYTKFgPV7aU",
    "tags": []
   },
   "source": [
    "- [ 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM](#1)\n",
    "  - [ 1.1 - Set up Kernel and Required Dependencies](#1.1)\n",
    "  - [ 1.2 - Load Dataset and LLM](#1.2)\n",
    "  - [ 1.3 - Test the Model with Zero Shot Inferencing](#1.3)\n",
    "- [ 2 - Perform Full Fine-Tuning](#2)\n",
    "  - [ 2.1 - Preprocess the Dialog-Summary Dataset](#2.1)\n",
    "  - [ 2.2 - Fine-Tune the Model with the Preprocessed Dataset](#2.2)\n",
    "  - [ 2.3 - Evaluate the Model Qualitatively (Human Evaluation)](#2.3)\n",
    "  - [ 2.4 - Evaluate the Model Quantitatively (with ROUGE Metric)](#2.4)\n",
    "- [ 3 - Perform Parameter Efficient Fine-Tuning (PEFT)](#3)\n",
    "  - [ 3.1 - Setup the PEFT/LoRA model for Fine-Tuning](#3.1)\n",
    "  - [ 3.2 - Train PEFT Adapter](#3.2)\n",
    "  - [ 3.3 - Evaluate the Model Qualitatively (Human Evaluation)](#3.3)\n",
    "  - [ 3.4 - Evaluate the Model Quantitatively (with ROUGE Metric)](#3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qBL7hyyV7aV"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Instalando PyTorch...\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch==2.8.0+cpu in ./mi_env/lib/python3.10/site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: torchvision in ./mi_env/lib/python3.10/site-packages (0.23.0+cpu)\n",
      "Requirement already satisfied: torchaudio in ./mi_env/lib/python3.10/site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: fsspec in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (2024.6.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (3.1.3)\n",
      "Requirement already satisfied: networkx in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (3.3)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (4.15.0)\n",
      "Requirement already satisfied: numpy in ./mi_env/lib/python3.10/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./mi_env/lib/python3.10/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./mi_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.8.0+cpu) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./mi_env/lib/python3.10/site-packages (from jinja2->torch==2.8.0+cpu) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "🚀 Instalando Transformers...\n",
      "Requirement already satisfied: transformers==4.56.1 in ./mi_env/lib/python3.10/site-packages (4.56.1)\n",
      "Requirement already satisfied: requests in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (4.67.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (2025.9.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (0.34.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (0.6.2)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (2.1.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (0.22.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.1) (4.15.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.1) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.1) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mi_env/lib/python3.10/site-packages (from requests->transformers==4.56.1) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mi_env/lib/python3.10/site-packages (from requests->transformers==4.56.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mi_env/lib/python3.10/site-packages (from requests->transformers==4.56.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mi_env/lib/python3.10/site-packages (from requests->transformers==4.56.1) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "🚀 Instalando Datasets...\n",
      "Requirement already satisfied: datasets==4.0.0 in ./mi_env/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (0.34.5)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (21.0.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (6.0.2)\n",
      "Requirement already satisfied: xxhash in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (3.5.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (2.32.5)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (2024.6.1)\n",
      "Requirement already satisfied: packaging in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (25.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (0.70.16)\n",
      "Requirement already satisfied: pandas in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (2.3.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./mi_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (3.12.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (1.1.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mi_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets==4.0.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mi_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets==4.0.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mi_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets==4.0.0) (2025.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mi_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets==4.0.0) (3.10)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./mi_env/lib/python3.10/site-packages (from pandas->datasets==4.0.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./mi_env/lib/python3.10/site-packages (from pandas->datasets==4.0.0) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./mi_env/lib/python3.10/site-packages (from pandas->datasets==4.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.20.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./mi_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==4.0.0) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "🚀 Instalando Evaluate...\n",
      "Requirement already satisfied: evaluate==0.4.5 in ./mi_env/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: multiprocess in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (2024.6.1)\n",
      "Requirement already satisfied: xxhash in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (3.5.0)\n",
      "Requirement already satisfied: dill in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (0.3.8)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (4.67.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (2.32.5)\n",
      "Requirement already satisfied: pandas in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (2.3.2)\n",
      "Requirement already satisfied: packaging in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (25.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (0.34.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (2.1.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./mi_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.5) (6.0.2)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.5) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./mi_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.5) (21.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./mi_env/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.5) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (1.1.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mi_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.5) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mi_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.5) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mi_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.5) (2025.8.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mi_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.5) (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./mi_env/lib/python3.10/site-packages (from pandas->evaluate==0.4.5) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./mi_env/lib/python3.10/site-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./mi_env/lib/python3.10/site-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.7.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.20.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (25.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.4.0)\n",
      "Requirement already satisfied: six>=1.5 in ./mi_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.5) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "🚀 Instalando ROUGE Score...\n",
      "Requirement already satisfied: rouge_score==0.1.2 in ./mi_env/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in ./mi_env/lib/python3.10/site-packages (from rouge_score==0.1.2) (2.3.1)\n",
      "Requirement already satisfied: nltk in ./mi_env/lib/python3.10/site-packages (from rouge_score==0.1.2) (3.9.1)\n",
      "Requirement already satisfied: numpy in ./mi_env/lib/python3.10/site-packages (from rouge_score==0.1.2) (2.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in ./mi_env/lib/python3.10/site-packages (from rouge_score==0.1.2) (1.17.0)\n",
      "Requirement already satisfied: tqdm in ./mi_env/lib/python3.10/site-packages (from nltk->rouge_score==0.1.2) (4.67.1)\n",
      "Requirement already satisfied: joblib in ./mi_env/lib/python3.10/site-packages (from nltk->rouge_score==0.1.2) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./mi_env/lib/python3.10/site-packages (from nltk->rouge_score==0.1.2) (2025.9.1)\n",
      "Requirement already satisfied: click in ./mi_env/lib/python3.10/site-packages (from nltk->rouge_score==0.1.2) (8.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "🚀 Instalando PEFT...\n",
      "Requirement already satisfied: peft==0.17.1 in ./mi_env/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: tqdm in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (2.8.0+cpu)\n",
      "Requirement already satisfied: packaging>=20.0 in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (25.0)\n",
      "Requirement already satisfied: transformers in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (4.56.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (2.1.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (0.34.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (1.10.1)\n",
      "Requirement already satisfied: psutil in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (7.0.0)\n",
      "Requirement already satisfied: safetensors in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (2024.6.1)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (3.13.1)\n",
      "Requirement already satisfied: requests in ./mi_env/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (1.1.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (4.15.0)\n",
      "Requirement already satisfied: jinja2 in ./mi_env/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.17.1) (3.1.3)\n",
      "Requirement already satisfied: networkx in ./mi_env/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.17.1) (3.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./mi_env/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.17.1) (1.13.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./mi_env/lib/python3.10/site-packages (from transformers->peft==0.17.1) (0.22.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./mi_env/lib/python3.10/site-packages (from transformers->peft==0.17.1) (2025.9.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./mi_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.17.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./mi_env/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.17.1) (2.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "🚀 Instalando dependencias adicionales...\n",
      "Requirement already satisfied: accelerate in ./mi_env/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: huggingface_hub in ./mi_env/lib/python3.10/site-packages (0.34.5)\n",
      "Requirement already satisfied: safetensors in ./mi_env/lib/python3.10/site-packages (0.6.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./mi_env/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./mi_env/lib/python3.10/site-packages (from accelerate) (2.8.0+cpu)\n",
      "Requirement already satisfied: pyyaml in ./mi_env/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: psutil in ./mi_env/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./mi_env/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: requests in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./mi_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in ./mi_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: networkx in ./mi_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./mi_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./mi_env/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "✨ ¡Instalación completada!\n",
      "\n",
      "🔍 Verificando instalaciones...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Verificación exitosa:\n",
      "   PyTorch: 2.8.0+cpu\n",
      "   Transformers: 4.56.1\n",
      "   Datasets: 4.0.0\n",
      "   PEFT: 0.17.1\n",
      "\n",
      "🎉 ¡Todo listo para hacer fine-tuning!\n"
     ]
    }
   ],
   "source": [
    "# Opción 1: Instalación paso a paso con comandos mágicos\n",
    "print(\"🚀 Instalando PyTorch...\")\n",
    "!pip install torch==2.8.0+cpu torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "print(\"🚀 Instalando Transformers...\")\n",
    "!pip install transformers==4.56.1\n",
    "\n",
    "print(\"🚀 Instalando Datasets...\")\n",
    "!pip install datasets==4.0.0\n",
    "\n",
    "print(\"🚀 Instalando Evaluate...\")\n",
    "!pip install evaluate==0.4.5\n",
    "\n",
    "print(\"🚀 Instalando ROUGE Score...\")\n",
    "!pip install rouge_score==0.1.2\n",
    "\n",
    "print(\"🚀 Instalando PEFT...\")\n",
    "!pip install peft==0.17.1\n",
    "\n",
    "print(\"🚀 Instalando dependencias adicionales...\")\n",
    "!pip install accelerate huggingface_hub safetensors\n",
    "\n",
    "print(\"✨ ¡Instalación completada!\")\n",
    "\n",
    "# Verificar instalaciones\n",
    "print(\"\\n🔍 Verificando instalaciones...\")\n",
    "try:\n",
    "    import torch\n",
    "    import transformers\n",
    "    import datasets\n",
    "    import evaluate\n",
    "    import peft\n",
    "    \n",
    "    print(\"✅ Verificación exitosa:\")\n",
    "    print(f\"   PyTorch: {torch.__version__}\")\n",
    "    print(f\"   Transformers: {transformers.__version__}\")\n",
    "    print(f\"   Datasets: {datasets.__version__}\")\n",
    "    print(f\"   PEFT: {peft.__version__}\")\n",
    "    print(\"\\n🎉 ¡Todo listo para hacer fine-tuning!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error en la verificación: {e}\")\n",
    "    print(\"Puede que necesites reiniciar el kernel del notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: loralib, torchdata\u001b[0m\u001b[33m\n",
      "\u001b[0mName: torch\n",
      "Version: 2.8.0+cpu\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: accelerate, peft, torchaudio, torchvision\n",
      "---\n",
      "Name: transformers\n",
      "Version: 4.56.1\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: peft\n",
      "---\n",
      "Name: datasets\n",
      "Version: 4.0.0\n",
      "Summary: HuggingFace community-driven open-source library of datasets\n",
      "Home-page: https://github.com/huggingface/datasets\n",
      "Author: HuggingFace Inc.\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache 2.0\n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyyaml, requests, tqdm, xxhash\n",
      "Required-by: evaluate\n",
      "---\n",
      "Name: evaluate\n",
      "Version: 0.4.5\n",
      "Summary: HuggingFace community-driven open-source library of evaluation\n",
      "Home-page: https://github.com/huggingface/evaluate\n",
      "Author: HuggingFace Inc.\n",
      "Author-email: leandro@huggingface.co\n",
      "License: Apache 2.0\n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: datasets, dill, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, requests, tqdm, xxhash\n",
      "Required-by: \n",
      "---\n",
      "Name: rouge-score\n",
      "Version: 0.1.2\n",
      "Summary: Pure python implementation of ROUGE-1.5.5.\n",
      "Home-page: https://github.com/google-research/google-research/tree/master/rouge\n",
      "Author: Google LLC\n",
      "Author-email: rouge-opensource@google.com\n",
      "License: \n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: absl-py, nltk, numpy, six\n",
      "Required-by: \n",
      "---\n",
      "Name: peft\n",
      "Version: 0.17.1\n",
      "Summary: Parameter-Efficient Fine-Tuning (PEFT)\n",
      "Home-page: https://github.com/huggingface/peft\n",
      "Author: The HuggingFace team\n",
      "Author-email: benjamin@huggingface.co\n",
      "License: Apache\n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: accelerate, huggingface_hub, numpy, packaging, psutil, pyyaml, safetensors, torch, tqdm, transformers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show torch torchdata transformers datasets evaluate rouge_score loralib peft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GV0mclXEV7aV"
   },
   "source": [
    "<a name='1.1'></a>\n",
    "### 1.1 - Set up Kernel and Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pFVij_p3V7aX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importe los componentes necesarios.\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtIOTMkrV7aX",
    "tags": []
   },
   "source": [
    "<a name='1.2'></a>\n",
    "### 1.2 - Cargar Dataset y LLM\n",
    "\n",
    "[Finance-Instruct-500k](https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k) es un dataset de Hugging Face especializado en instrucciones financieras. Contiene más de 500,000 ejemplos de instrucciones financieras con sus respectivas respuestas, perfecto para fine-tuning con LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "52e88adfc6324f06a2957699938e349f",
      "1c727073a23e4c29a685221fc2c8297d",
      "20e73a01ed92416f9111b87ea630c1ec",
      "d137e6f6e7d14bd68b13c9ffff7444b6",
      "8e35b400ff644bd4af0079392a461000",
      "7af87c4f3c0f4ad7ad90c5b835743f8c",
      "",
      "848d8e40c254442b8cc93c64c7176dcd"
     ]
    },
    "id": "hmH9Or7RV7aY",
    "outputId": "610d1c04-7334-4417-d894-75b0c3828f0a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Josephgflowers/Finance-Instruct-500k\", split=\"train[:10000]\")  # Solo primeros 10K ejemplos\n",
    "\n",
    "# Convertir a DatasetDict si necesitas splits\n",
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict({\"train\": dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system': Value('string'), 'user': Value('string'), 'assistant': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"].features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBsjjW4OV7aY",
    "tags": []
   },
   "source": [
    "Cargamos el modelo pre-entrenado [T5-small](https://huggingface.co/t5-small) y su tokenizador directamente desde HuggingFace. T5-small es una versión más liviana con solo 60M parámetros, ideal para fine-tuning rápido con LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "681aacbb846341d68528367bf1e6ea5e",
      "4e0a9c5d95cb4edf87322c51dc4b6ad7",
      "055404322df7485a9276138114ecb109",
      "5200456208324ff5b5daafd329e11a67",
      "e8fe83c03ef94d50a02233c5c4776e14",
      "ab65d51105de4aac840a2f3a27291ffb",
      "2e0dbf02a6fc4deab0e7b59375fcd9a2"
     ]
    },
    "id": "SsEMZw1CV7aY",
    "outputId": "89265c6d-4e74-486e-8c76-c73a7a9a174a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargamos el modelo y el tokenizador\n",
    "\n",
    "model_name='google/flan-t5-small'\n",
    "# model_name='t5-google/flan-t5-small'\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir7FTf20V7aY",
    "tags": []
   },
   "source": [
    "Es posible extraer la cantidad de parámetros del modelo y descubrir cuántos de ellos se pueden entrenar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dYnW_pqiV7aY",
    "outputId": "0eae56e9-4dd9-4cfe-97fc-4233f73c04fd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros entrenables del modelo: 76,961,152\n",
      " Total de parametros del modelo: 76,961,152\n",
      " Porcentaje de parametros entrenables 100%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"Parametros entrenables del modelo: {trainable_model_params:,.0f}\\n Total de parametros del modelo: {all_model_params:,.0f}\\n Porcentaje de parametros entrenables {100 * trainable_model_params / all_model_params:.0f}%\"\n",
    "#print(f'El area es: {area:,.2f}')\n",
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Explorando el dataset Finance-Instruct-500k...\n",
      "Splits disponibles: ['train']\n",
      "Tipo de dataset: <class 'datasets.dataset_dict.DatasetDict'>\n",
      "\n",
      "📊 Split 'train':\n",
      "   - Cantidad de ejemplos: 10000\n",
      "   - Columnas: ['system', 'user', 'assistant']\n",
      "\n",
      "📝 Ejemplo del split 'train':\n",
      "   - user: Explain tradeoffs between fiscal and monetary policy as tools in a nation's economic toolkit. Provid...\n",
      "   - assistant: Fiscal and monetary policy are the two main tools that governments have to influence economic activi...\n"
     ]
    }
   ],
   "source": [
    "# Verificar la estructura del dataset Finance-Instruct-500k\n",
    "print(\"🔍 Explorando el dataset Finance-Instruct-500k...\")\n",
    "print(f\"Splits disponibles: {list(dataset.keys())}\")\n",
    "print(f\"Tipo de dataset: {type(dataset)}\")\n",
    "\n",
    "# Ver información de cada split disponible\n",
    "for split_name in dataset.keys():\n",
    "    print(f\"\\n📊 Split '{split_name}':\")\n",
    "    print(f\"   - Cantidad de ejemplos: {len(dataset[split_name])}\")\n",
    "    print(f\"   - Columnas: {list(dataset[split_name].features.keys())}\")\n",
    "\n",
    "# Mostrar un ejemplo del primer split disponible\n",
    "first_split = list(dataset.keys())[0]\n",
    "print(f\"\\n📝 Ejemplo del split '{first_split}':\")\n",
    "print(f\"   - user: {dataset[first_split][0]['user'][:100]}...\")\n",
    "print(f\"   - assistant: {dataset[first_split][0]['assistant'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Creando divisiones manuales del dataset...\n",
      "El dataset solo tiene 'train'. Dividiendo manualmente...\n",
      "Total de ejemplos: 10,000\n",
      "📊 División propuesta:\n",
      "   - Train: 0 a 7,000 (70%)\n",
      "   - Validation: 7,000 a 8,500 (15%)\n",
      "   - Test: 8,500 a 10,000 (15%)\n",
      "✅ Dataset dividido exitosamente!\n",
      "   - Train: 7,000 ejemplos\n",
      "   - Validation: 1,500 ejemplos\n",
      "   - Test: 1,500 ejemplos\n"
     ]
    }
   ],
   "source": [
    "# Dividir manualmente el dataset si solo tiene 'train'\n",
    "print(\"🛠️ Creando divisiones manuales del dataset...\")\n",
    "\n",
    "if len(dataset.keys()) == 1 and 'train' in dataset.keys():\n",
    "    print(\"El dataset solo tiene 'train'. Dividiendo manualmente...\")\n",
    "    \n",
    "    # Obtener el total de ejemplos\n",
    "    total_examples = len(dataset['train'])\n",
    "    print(f\"Total de ejemplos: {total_examples:,}\")\n",
    "    \n",
    "    # Definir índices para cada split (puedes ajustar estos porcentajes)\n",
    "    train_end = int(0.7 * total_examples)      # 70% para entrenamiento\n",
    "    val_end = int(0.85 * total_examples)       # 15% para validación  \n",
    "    # El resto (15%) será para test\n",
    "    \n",
    "    print(f\"📊 División propuesta:\")\n",
    "    print(f\"   - Train: 0 a {train_end:,} ({70}%)\")\n",
    "    print(f\"   - Validation: {train_end:,} a {val_end:,} ({15}%)\")  \n",
    "    print(f\"   - Test: {val_end:,} a {total_examples:,} ({15}%)\")\n",
    "    \n",
    "    # Crear los nuevos splits manualmente\n",
    "    train_data = dataset['train'].select(range(0, train_end))\n",
    "    val_data = dataset['train'].select(range(train_end, val_end))\n",
    "    test_data = dataset['train'].select(range(val_end, total_examples))\n",
    "    \n",
    "    # Crear el nuevo diccionario de dataset\n",
    "    from datasets import DatasetDict\n",
    "    dataset = DatasetDict({\n",
    "        'train': train_data,\n",
    "        'validation': val_data,\n",
    "        'test': test_data\n",
    "    })\n",
    "    \n",
    "    print(\"✅ Dataset dividido exitosamente!\")\n",
    "    print(f\"   - Train: {len(dataset['train']):,} ejemplos\")\n",
    "    print(f\"   - Validation: {len(dataset['validation']):,} ejemplos\")\n",
    "    print(f\"   - Test: {len(dataset['test']):,} ejemplos\")\n",
    "\n",
    "else:\n",
    "    print(\"El dataset ya tiene múltiples splits:\")\n",
    "    for split_name in dataset.keys():\n",
    "        print(f\"   - {split_name}: {len(dataset[split_name]):,} ejemplos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbNtotpbV7aZ",
    "tags": []
   },
   "source": [
    "<a name='1.3'></a>\n",
    "### 1.3 - Prueba del modelo con Zero Shot Inferencing\n",
    "\n",
    "Pruebe el modelo con la inferencia de tiro cero. Puede ver que el modelo tiene dificultades para resumir el diálogo en comparación con el resumen de referencia, pero extrae información importante del texto que indica que el modelo se puede ajustar a la tarea en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ruNKVIGEV7aZ",
    "outputId": "25596b54-9780-47a5-83eb-80ec09e2d111",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      " PROMPT DE ENTRADA:\n",
      "\n",
      "financial instruction: As a math student with a background in applied mathematics and numerics, how can I transition into the field of mathematical finance without prior knowledge in finance or economics?\n",
      "\n",
      "Answer:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "RESPUESTA HUMANA (BASELINE) :\n",
      "To transition into mathematical finance without prior knowledge in the field, consider the following steps:\n",
      "\n",
      "* Acquire foundational knowledge: Begin by reading introductory books on finance and economics, such as \"Investment Science\" by Luenberger.\n",
      "* Study mathematical finance: Enroll in courses or read books on mathematical finance, such as \"Stochastic Calculus for Finance\" by Steven Shreve or \"Monte Carlo Methods in Financial Engineering\" by Glasserman.\n",
      "* Build a strong statistical foundation: Focus on mastering multivariate statistics and time series analysis.\n",
      "* Improve linear algebra skills: Advance your understanding of matrix analysis and functional analysis.\n",
      "* Explore related topics: Investigate areas where your existing knowledge intersects with finance, such as stochastic differential equations and random processes.\n",
      "* Consider attending relevant lectures: Identify and attend university lectures that cover topics in mathematical finance.\n",
      "* Learn financial software: Familiarize yourself with programming languages and software used in finance, such as R or Python.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "RESPUESTA GENERADA POR EL MODELO CON ZERO SHOT:\n",
      "a mathematical education\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "\n",
    "# Extraemos la instrucción y respuesta del nuevo dataset\n",
    "instruction = dataset['test'][index]['user']\n",
    "expected_response = dataset['test'][index]['assistant']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "financial instruction: {instruction}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    original_model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=200,\n",
    "    )[0],\n",
    "    skip_special_tokens=True \n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f' PROMPT DE ENTRADA:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'RESPUESTA HUMANA (BASELINE) :\\n{expected_response}\\n')\n",
    "print(dash_line)\n",
    "print(f'RESPUESTA GENERADA POR EL MODELO CON ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-zTt-k9V7aZ",
    "tags": []
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Realizar Full Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7EhKQABV7aZ",
    "tags": []
   },
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - Preprocesar el dataset Dialog-Summary\n",
    "\n",
    "Se necesita convertir los pares dialogo-resumen (prompt-response) en instrucciones explícitas para el LLM. Agregar una instrucción al inicio del dialogo como `Summarize the following conversation` y al inicio del resumen agregar `Summary`como se muestra a continuación:\n",
    "\n",
    "Training prompt (dialogue):\n",
    "```\n",
    "Summarize the following conversation.\n",
    "\n",
    "    Chris: This is his part of the conversation.\n",
    "    Antje: This is her part of the conversation.\n",
    "    \n",
    "Summary:\n",
    "```\n",
    "\n",
    "Training response (summary):\n",
    "```\n",
    "Both Chris and Antje participated in the conversation.\n",
    "```\n",
    "\n",
    "Then preprocess the prompt-response dataset into tokens and pull out their `input_ids` (1 per token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      ""
     ]
    },
    "id": "kQd6neWAV7aZ",
    "outputId": "1e2c96f5-4b37-472c-f239-d5a206cc8dab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of prompt list:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  67%|██████▋   | 1000/1500 [00:01<00:00, 677.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of prompt list:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1500/1500 [00:02<00:00, 664.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    # El dataset Finance-Instruct-500k tiene 'user' (instrucción) y 'assistant' (respuesta)\n",
    "    # Formato: \"Instrucción: <user>\\n\\nRespuesta: \"\n",
    "    start_prompt = 'Instrucción financiera: '\n",
    "    end_prompt = '\\n\\nRespuesta: '\n",
    "    \n",
    "    # Construimos el prompt para cada ejemplo en el batch\n",
    "    prompt = [start_prompt + instruction + end_prompt for instruction in example[\"user\"]]\n",
    "    print(\"Size of prompt list: \", len(prompt))  # Imprimir el tamaño de la lista\n",
    "    \n",
    "    # Tokenizamos los prompts (inputs)\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    # Tokenizamos las respuestas (labels)\n",
    "    example['labels'] = tokenizer(example[\"assistant\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    return example\n",
    "\n",
    "# El dataset Finance-Instruct-500k contiene 3 splits: train, validation, test\n",
    "# La función tokenize_function procesa todos los datos en batches\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Removemos las columnas originales, manteniendo solo input_ids y labels\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['system', 'user', 'assistant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 1\n",
      "})\n",
      "Column([[29169, 11, 3, 14356, 1291, 33, 8, 192, 711, 1339, 24, 10524, 43, 12, 2860, 1456, 1756, 5, 328, 284, 43, 1393, 11, 3314, 1549, 7, 5, 29169, 1291, 2401, 7, 12, 789, 2887, 11, 1104, 257, 3055, 5, 19119, 13, 5043, 1291, 560, 10, 1697, 3, 2092, 8, 1651, 419, 19988, 6, 8, 412, 5, 134, 5, 789, 6960, 3, 9, 5043, 26544, 190, 8, 797, 16532, 11, 419, 15601, 297, 1983, 13, 10425, 100, 1285, 1936, 2887, 30, 3620, 6, 1104, 8620, 6, 11, 8148, 17646, 1393, 5, 37, 8762, 47, 12, 4888, 12955, 2173, 11, 14954, 1456, 1756, 5, 6536, 43, 435, 24, 8, 26544, 141, 3, 9, 1465, 68, 11306, 1113, 30, 1456, 1170, 5, 1697, 37, 2523, 3602, 6960, 1104, 8620, 16, 1233, 28, 8, 1288, 13, 3094, 268, 1729, 11, 1170, 5, 611, 6, 8, 1504, 30, 1170, 65, 118, 5054, 26, 6, 11, 8, 1104, 8620, 4019, 1936, 8, 2822, 1487, 11724, 5, 1290, 1582, 1208, 1291, 2401, 7, 12, 3055, 57, 3, 9, 2069, 2137, 6, 114, 8, 5034, 9473, 6, 81, 1046, 1917, 11, 8, 540, 1899, 5, 19119, 13, 3, 14356, 1291, 560, 10, 1697, 621, 8, 2628, 981, 5362, 6, 8, 10803, 3, 22055, 1046, 1917, 12, 1084, 5733, 11, 6960, 18906, 3, 16927, 1356, 12, 993, 27605, 5, 37, 8762, 47, 12, 4888, 16391, 6, 1729, 6, 11, 3733, 2887, 5, 506, 2874, 33, 3, 16473, 28, 2022, 8, 2717, 8303, 5, 1697, 86, 8, 1480, 5541, 7, 6, 8, 10803, 3279, 1046, 1917, 12, 1428, 12485, 1208, 1666, 7, 45, 1456, 1170, 5, 16808, 1917, 9859, 12, 2684, 53, 8, 2717, 11, 3, 16217, 3, 9, 22440, 16, 1596, 5, 37, 843, 1668, 1647, 7, 33, 10, 1697, 29169, 1291, 54, 43, 3, 9, 72, 7774, 1113, 68, 1217, 1200, 12, 4028, 788, 12, 8, 1827, 433, 5, 1290, 1582, 1208, 1291, 19, 72, 3, 29, 603, 2296, 68, 65, 3, 9, 3, 13627, 2860, 30, 8, 2717, 5, 1697, 29169, 1291, 11737, 8, 1487, 11724, 6, 298, 3, 14356, 1291, 405, 59, 1461, 2603, 789, 2814, 5, 611, 6, 182, 731, 1046, 1917, 788, 12, 3, 14356, 1291, 54, 2454, 1146, 789, 24564, 5, 1697, 1290, 1582, 1208, 1291, 2134, 7, 12, 36, 705, 22937, 738, 2936, 6, 298, 5043, 1291, 12152, 557, 522, 72, 8263, 5, 86, 9251, 6, 321, 1339, 43, 7796, 11, 6900, 11, 161, 200, 16, 26947, 12, 21323, 8, 2717, 11, 11072, 1170, 5, 37, 6624, 2153, 5619, 30, 8, 806, 1456, 1124, 11, 1291, 1766, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print (type(tokenized_datasets))\n",
    "first_example = tokenized_datasets[\"train\"].select([0])\n",
    "print(first_example)\n",
    "print(first_example['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8HypBOxV7aa",
    "tags": []
   },
   "source": [
    "Para ahorrar algo de tiempo en el laboratorio, submuestreará el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      ""
     ]
    },
    "id": "S2qI0XRXV7aa",
    "outputId": "ee9215a9-f571-4405-d443-0850ec92439d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/1500 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 1500/1500 [00:01<00:00, 1101.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcZHpjXiV7aa",
    "tags": []
   },
   "source": [
    "Compruebe las formas de las tres partes del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Zzg-w16UV7aa",
    "outputId": "3f2b7e80-d13a-43cc-d90a-54ec85528478",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (70, 2)\n",
      "Validation: (15, 2)\n",
      "Test: (15, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 70\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 15\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 15\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4sYS5pDV7aa"
   },
   "source": [
    "El dataset de salida esta listo para el fine-tunning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aBoXNXzV7ap"
   },
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Fine tunning Eficiente de Parámetros (PEFT)\n",
    "\n",
    "Ahora, realicemos un ajuste fino **PEFT** en lugar del ajuste fino completo, como se hizo anteriormente. PEFT es una forma de ajuste fino de instrucciones mucho más eficiente que el ajuste fino completo, con resultados de evaluación comparables, como verá pronto.\n",
    "\n",
    "PEFT es un término genérico que incluye **Adaptación de Bajo Rango (LoRA)** y ajuste de prompts (¡que NO ES LO MISMO que ingeniería de prompts!). En la mayoría de los casos, cuando alguien habla de PEFT, se refiere a LoRA. LoRA, a un nivel muy alto, permite al usuario ajustar su modelo utilizando menos recursos computacionales (en algunos casos, una sola GPU). Después del ajuste fino para una tarea, caso de uso o inquilino específico con LoRA, el resultado es que el LLM original permanece sin cambios y surge un nuevo \"adaptador LoRA\". Este adaptador LoRA es mucho más pequeño que el LLM original: aproximadamente un porcentaje de un solo dígito del tamaño del LLM original (MB vs. GB).\n",
    "\n",
    "No obstante, en el momento de la inferencia, el adaptador LoRA debe reunirse y combinarse con su LLM original para atender la solicitud de inferencia. La ventaja, sin embargo, es que muchos adaptadores LoRA pueden reutilizar el LLM original, lo que reduce los requisitos generales de memoria al atender múltiples tareas y casos de uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9hjS-tsV7ap"
   },
   "source": [
    "<a name='3.1'></a>\n",
    "\n",
    "\n",
    "### 3.1 - Configuración del modelo PEFT/LoRA para el ajuste fino\n",
    "\n",
    "Debe configurar el modelo PEFT/LoRA para el ajuste fino con un nuevo adaptador de capa/parámetro. Al usar PEFT/LoRA, se congela el LLM subyacente y solo se entrena el adaptador. Observe la configuración de LoRA a continuación. Observe el hiperparámetro de rango (`r`), que define el rango/dimensión del adaptador que se va a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iOjoDSwWV7ap",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMIM04QQV7ap",
    "tags": []
   },
   "source": [
    "Add LoRA adapter layers/parameters to the original LLM to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LnFsAZn-V7aq",
    "outputId": "f51c1974-cbb5-41ab-9fc9-33c458a7f804",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros entrenables del modelo: 1,376,256\n",
      " Total de parametros del modelo: 78,337,408\n",
      " Porcentaje de parametros entrenables 2%\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(original_model,\n",
    "                            lora_config)\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_ONKxTAV7aq",
    "tags": []
   },
   "source": [
    "<a name='3.2'></a>\n",
    "### 3.2 - Train PEFT Adapter\n",
    "\n",
    "Define training arguments and create `Trainer` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CN-Dbz23V7aq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = f'./peft-finance-instruct-training-{str(int(time.time()))}'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=1,\n",
    "    max_steps=5\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHBCtG41V7aq"
   },
   "source": [
    "Now everything is ready to train the PEFT adapter and save the model.\n",
    "\n",
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DpmZQBsMV7aq",
    "outputId": "190e13b1-4dfe-4fd6-ea51-5da0c34eaf98",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 1:09:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>15.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./peft-dialogue-summary-checkpoint-local/tokenizer_config.json',\n",
       " './peft-dialogue-summary-checkpoint-local/special_tokens_map.json',\n",
       " './peft-dialogue-summary-checkpoint-local/spiece.model',\n",
       " './peft-dialogue-summary-checkpoint-local/added_tokens.json',\n",
       " './peft-dialogue-summary-checkpoint-local/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.train()\n",
    "peft_model_path=\"./peft-dialogue-summary-checkpoint-local\"\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3voqLpwV7aq",
    "tags": []
   },
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "886lESmdV7ar",
    "tags": []
   },
   "source": [
    "Prepare este modelo añadiendo un adaptador al modelo FLAN-T5 original. Está configurando `is_trainable=False` porque el plan es realizar inferencia únicamente con este modelo PEFT. Si estuviera preparando el modelo para entrenamiento posterior, debería configurar `is_trainable=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5FCVCdu8V7ar",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
    "                                       './peft-dialogue-summary-checkpoint-local/',\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uretNB0sV7ar",
    "tags": []
   },
   "source": [
    "The number of trainable parameters will be `0` due to `is_trainable=False` setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HqWoJBCrV7ar",
    "outputId": "0377ef7e-bd4a-42af-d559-788b9c4b6b89",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros entrenables del modelo: 0\n",
      " Total de parametros del modelo: 78,337,408\n",
      " Porcentaje de parametros entrenables 0%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywXzSfTrV7ar"
   },
   "source": [
    "<a name='3.3'></a>\n",
    "### 3.3 - Evaluate the Model Qualitatively (Human Evaluation)\n",
    "\n",
    "Make inferences for the same example as in sections [1.3](#1.3) and [2.3](#2.3), with the original model, fully fine-tuned and PEFT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Cpcpbtj1V7as",
    "outputId": "ffd18e06-ab2c-438e-86bd-4b27af6644e8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "INSTRUCCIÓN FINANCIERA:\n",
      "As a math student with a background in applied mathematics and numerics, how can I transition into the field of mathematical finance without prior knowledge in finance or economics?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RESPUESTA HUMANA (BASELINE):\n",
      "To transition into mathematical finance without prior knowledge in the field, consider the following steps:\n",
      "\n",
      "* Acquire foundational knowledge: Begin by reading introductory books on finance and economics, such as \"Investment Science\" by Luenberger.\n",
      "* Study mathematical finance: Enroll in courses or read books on mathematical finance, such as \"Stochastic Calculus for Finance\" by Steven Shreve or \"Monte Carlo Methods in Financial Engineering\" by Glasserman.\n",
      "* Build a strong statistical foundation: Focus on mastering multivariate statistics and time series analysis.\n",
      "* Improve linear algebra skills: Advance your understanding of matrix analysis and functional analysis.\n",
      "* Explore related topics: Investigate areas where your existing knowledge intersects with finance, such as stochastic differential equations and random processes.\n",
      "* Consider attending relevant lectures: Identify and attend university lectures that cover topics in mathematical finance.\n",
      "* Learn financial software: Familiarize yourself with programming languages and software used in finance, such as R or Python.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MODELO ORIGINAL (google/flan-t5-small):\n",
      "Financial instruction: As a math student with a background in applied mathematics and numerics,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MODELO PEFT (google/flan-t5-small + LoRA):\n",
      "a financial education\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dash_line = '-' * 100\n",
    "\n",
    "# Seleccionar un ejemplo del dataset\n",
    "index = 200\n",
    "instruction = dataset['test'][index]['user']\n",
    "expected_response = dataset['test'][index]['assistant']\n",
    "\n",
    "# Como no tienes instruct_model, compararemos solo original vs PEFT\n",
    "# El formato correcto para Finance-Instruct es diferente al de diálogos\n",
    "prompt = f\"\"\"\n",
    "Financial instruction: {instruction}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generar respuestas\n",
    "original_model_outputs = original_model.generate(\n",
    "    input_ids=input_ids, \n",
    "    generation_config=GenerationConfig(max_new_tokens=200, num_beams=1)\n",
    ")\n",
    "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "peft_model_outputs = peft_model.generate(\n",
    "    input_ids=input_ids, \n",
    "    generation_config=GenerationConfig(max_new_tokens=200, num_beams=1)\n",
    ")\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Mostrar comparación\n",
    "print(dash_line)\n",
    "print(f'INSTRUCCIÓN FINANCIERA:\\n{instruction}')\n",
    "print(dash_line)\n",
    "print(f'RESPUESTA HUMANA (BASELINE):\\n{expected_response}')\n",
    "print(dash_line)\n",
    "print(f'MODELO ORIGINAL (google/flan-t5-small):\\n{original_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'MODELO PEFT (google/flan-t5-small + LoRA):\\n{peft_model_text_output}')\n",
    "print(dash_line)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "mi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
