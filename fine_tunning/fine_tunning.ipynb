{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/armandoordonez/GenAI/blob/main/Lab_2_fine_tune_generative_ai_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzpMK6XbV7aR",
    "tags": []
   },
   "source": [
    "# Fine-Tune un modelo de Gen AI Model para res√∫menes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObK2CXbTV7aT"
   },
   "source": [
    "En este cuaderno, se har√° en fine-tune de un LLM existente de Hugging Face para mejorar el resumen de los di√°logos. Utilizar√° el modelo [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5), que proporciona un modelo tuneado con instrucciones de alta calidad y puede resumir texto. Para mejorar las inferencias, se usar√° full fine-tuning y evaluar√° los resultados con m√©tricas de ROUGE. Luego, se usar√° Parameter Efficient Fine-Tuning (PEFT), evaluar√° el modelo resultante y ver√° que los beneficios de PEFT superan las desventajas de rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PE1nZWSwV7aU"
   },
   "source": [
    "# Tabla de contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuYTKFgPV7aU",
    "tags": []
   },
   "source": [
    "- [ 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM](#1)\n",
    "  - [ 1.1 - Set up Kernel and Required Dependencies](#1.1)\n",
    "  - [ 1.2 - Load Dataset and LLM](#1.2)\n",
    "  - [ 1.3 - Test the Model with Zero Shot Inferencing](#1.3)\n",
    "- [ 2 - Perform Full Fine-Tuning](#2)\n",
    "  - [ 2.1 - Preprocess the Dialog-Summary Dataset](#2.1)\n",
    "  - [ 2.2 - Fine-Tune the Model with the Preprocessed Dataset](#2.2)\n",
    "  - [ 2.3 - Evaluate the Model Qualitatively (Human Evaluation)](#2.3)\n",
    "  - [ 2.4 - Evaluate the Model Quantitatively (with ROUGE Metric)](#2.4)\n",
    "- [ 3 - Perform Parameter Efficient Fine-Tuning (PEFT)](#3)\n",
    "  - [ 3.1 - Setup the PEFT/LoRA model for Fine-Tuning](#3.1)\n",
    "  - [ 3.2 - Train PEFT Adapter](#3.2)\n",
    "  - [ 3.3 - Evaluate the Model Qualitatively (Human Evaluation)](#3.3)\n",
    "  - [ 3.4 - Evaluate the Model Quantitatively (with ROUGE Metric)](#3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qBL7hyyV7aV"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Set up Kernel, Load Required Dependencies, Dataset and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Instalando PyTorch...\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch==2.8.0+cpu in ./mi_env/lib/python3.10/site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: torchvision in ./mi_env/lib/python3.10/site-packages (0.23.0+cpu)\n",
      "Requirement already satisfied: torchaudio in ./mi_env/lib/python3.10/site-packages (2.8.0+cpu)\n",
      "Requirement already satisfied: fsspec in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (2024.6.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (3.1.3)\n",
      "Requirement already satisfied: networkx in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (3.3)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./mi_env/lib/python3.10/site-packages (from torch==2.8.0+cpu) (4.15.0)\n",
      "Requirement already satisfied: numpy in ./mi_env/lib/python3.10/site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./mi_env/lib/python3.10/site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./mi_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.8.0+cpu) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./mi_env/lib/python3.10/site-packages (from jinja2->torch==2.8.0+cpu) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "üöÄ Instalando Transformers...\n",
      "Requirement already satisfied: transformers==4.56.1 in ./mi_env/lib/python3.10/site-packages (4.56.1)\n",
      "Requirement already satisfied: requests in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (4.67.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (2025.9.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (0.34.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (0.6.2)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (2.1.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (0.22.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./mi_env/lib/python3.10/site-packages (from transformers==4.56.1) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.1) (4.15.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.1) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.56.1) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mi_env/lib/python3.10/site-packages (from requests->transformers==4.56.1) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mi_env/lib/python3.10/site-packages (from requests->transformers==4.56.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mi_env/lib/python3.10/site-packages (from requests->transformers==4.56.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mi_env/lib/python3.10/site-packages (from requests->transformers==4.56.1) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "üöÄ Instalando Datasets...\n",
      "Requirement already satisfied: datasets==4.0.0 in ./mi_env/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (0.34.5)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (2.1.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (21.0.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (6.0.2)\n",
      "Requirement already satisfied: xxhash in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (3.5.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (2.32.5)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (2024.6.1)\n",
      "Requirement already satisfied: packaging in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (25.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (0.70.16)\n",
      "Requirement already satisfied: pandas in ./mi_env/lib/python3.10/site-packages (from datasets==4.0.0) (2.3.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./mi_env/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (3.12.15)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (1.1.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mi_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets==4.0.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mi_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets==4.0.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mi_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets==4.0.0) (2025.8.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mi_env/lib/python3.10/site-packages (from requests>=2.32.2->datasets==4.0.0) (3.10)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./mi_env/lib/python3.10/site-packages (from pandas->datasets==4.0.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./mi_env/lib/python3.10/site-packages (from pandas->datasets==4.0.0) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./mi_env/lib/python3.10/site-packages (from pandas->datasets==4.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.20.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (25.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.7.0)\n",
      "Requirement already satisfied: six>=1.5 in ./mi_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==4.0.0) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "üöÄ Instalando Evaluate...\n",
      "Requirement already satisfied: evaluate==0.4.5 in ./mi_env/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: multiprocess in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (2024.6.1)\n",
      "Requirement already satisfied: xxhash in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (3.5.0)\n",
      "Requirement already satisfied: dill in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (0.3.8)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (4.67.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (2.32.5)\n",
      "Requirement already satisfied: pandas in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (2.3.2)\n",
      "Requirement already satisfied: packaging in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (25.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (0.34.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (2.1.2)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./mi_env/lib/python3.10/site-packages (from evaluate==0.4.5) (4.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./mi_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.5) (6.0.2)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.5) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./mi_env/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate==0.4.5) (21.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./mi_env/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.5) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mi_env/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.5) (1.1.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mi_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.5) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mi_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.5) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mi_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.5) (2025.8.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mi_env/lib/python3.10/site-packages (from requests>=2.19.0->evaluate==0.4.5) (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./mi_env/lib/python3.10/site-packages (from pandas->evaluate==0.4.5) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./mi_env/lib/python3.10/site-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./mi_env/lib/python3.10/site-packages (from pandas->evaluate==0.4.5) (2025.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.7.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.20.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (25.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./mi_env/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate==0.4.5) (1.4.0)\n",
      "Requirement already satisfied: six>=1.5 in ./mi_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.5) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "üöÄ Instalando ROUGE Score...\n",
      "Requirement already satisfied: rouge_score==0.1.2 in ./mi_env/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in ./mi_env/lib/python3.10/site-packages (from rouge_score==0.1.2) (2.3.1)\n",
      "Requirement already satisfied: nltk in ./mi_env/lib/python3.10/site-packages (from rouge_score==0.1.2) (3.9.1)\n",
      "Requirement already satisfied: numpy in ./mi_env/lib/python3.10/site-packages (from rouge_score==0.1.2) (2.1.2)\n",
      "Requirement already satisfied: six>=1.14.0 in ./mi_env/lib/python3.10/site-packages (from rouge_score==0.1.2) (1.17.0)\n",
      "Requirement already satisfied: tqdm in ./mi_env/lib/python3.10/site-packages (from nltk->rouge_score==0.1.2) (4.67.1)\n",
      "Requirement already satisfied: joblib in ./mi_env/lib/python3.10/site-packages (from nltk->rouge_score==0.1.2) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./mi_env/lib/python3.10/site-packages (from nltk->rouge_score==0.1.2) (2025.9.1)\n",
      "Requirement already satisfied: click in ./mi_env/lib/python3.10/site-packages (from nltk->rouge_score==0.1.2) (8.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "üöÄ Instalando PEFT...\n",
      "Requirement already satisfied: peft==0.17.1 in ./mi_env/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: tqdm in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (2.8.0+cpu)\n",
      "Requirement already satisfied: packaging>=20.0 in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (25.0)\n",
      "Requirement already satisfied: transformers in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (4.56.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (2.1.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (0.34.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (1.10.1)\n",
      "Requirement already satisfied: psutil in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (7.0.0)\n",
      "Requirement already satisfied: safetensors in ./mi_env/lib/python3.10/site-packages (from peft==0.17.1) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (2024.6.1)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (3.13.1)\n",
      "Requirement already satisfied: requests in ./mi_env/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (1.1.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.17.1) (4.15.0)\n",
      "Requirement already satisfied: jinja2 in ./mi_env/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.17.1) (3.1.3)\n",
      "Requirement already satisfied: networkx in ./mi_env/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.17.1) (3.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./mi_env/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.17.1) (1.13.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./mi_env/lib/python3.10/site-packages (from transformers->peft==0.17.1) (0.22.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./mi_env/lib/python3.10/site-packages (from transformers->peft==0.17.1) (2025.9.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./mi_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.17.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./mi_env/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.17.1) (2.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.17.1) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "üöÄ Instalando dependencias adicionales...\n",
      "Requirement already satisfied: accelerate in ./mi_env/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: huggingface_hub in ./mi_env/lib/python3.10/site-packages (0.34.5)\n",
      "Requirement already satisfied: safetensors in ./mi_env/lib/python3.10/site-packages (0.6.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./mi_env/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./mi_env/lib/python3.10/site-packages (from accelerate) (2.8.0+cpu)\n",
      "Requirement already satisfied: pyyaml in ./mi_env/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: psutil in ./mi_env/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./mi_env/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: filelock in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: requests in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (2.32.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./mi_env/lib/python3.10/site-packages (from huggingface_hub) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./mi_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in ./mi_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: networkx in ./mi_env/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./mi_env/lib/python3.10/site-packages (from requests->huggingface_hub) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./mi_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./mi_env/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "‚ú® ¬°Instalaci√≥n completada!\n",
      "\n",
      "üîç Verificando instalaciones...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Verificaci√≥n exitosa:\n",
      "   PyTorch: 2.8.0+cpu\n",
      "   Transformers: 4.56.1\n",
      "   Datasets: 4.0.0\n",
      "   PEFT: 0.17.1\n",
      "\n",
      "üéâ ¬°Todo listo para hacer fine-tuning!\n"
     ]
    }
   ],
   "source": [
    "# Opci√≥n 1: Instalaci√≥n paso a paso con comandos m√°gicos\n",
    "print(\"üöÄ Instalando PyTorch...\")\n",
    "!pip install torch==2.8.0+cpu torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "print(\"üöÄ Instalando Transformers...\")\n",
    "!pip install transformers==4.56.1\n",
    "\n",
    "print(\"üöÄ Instalando Datasets...\")\n",
    "!pip install datasets==4.0.0\n",
    "\n",
    "print(\"üöÄ Instalando Evaluate...\")\n",
    "!pip install evaluate==0.4.5\n",
    "\n",
    "print(\"üöÄ Instalando ROUGE Score...\")\n",
    "!pip install rouge_score==0.1.2\n",
    "\n",
    "print(\"üöÄ Instalando PEFT...\")\n",
    "!pip install peft==0.17.1\n",
    "\n",
    "print(\"üöÄ Instalando dependencias adicionales...\")\n",
    "!pip install accelerate huggingface_hub safetensors\n",
    "\n",
    "print(\"‚ú® ¬°Instalaci√≥n completada!\")\n",
    "\n",
    "# Verificar instalaciones\n",
    "print(\"\\nüîç Verificando instalaciones...\")\n",
    "try:\n",
    "    import torch\n",
    "    import transformers\n",
    "    import datasets\n",
    "    import evaluate\n",
    "    import peft\n",
    "    \n",
    "    print(\"‚úÖ Verificaci√≥n exitosa:\")\n",
    "    print(f\"   PyTorch: {torch.__version__}\")\n",
    "    print(f\"   Transformers: {transformers.__version__}\")\n",
    "    print(f\"   Datasets: {datasets.__version__}\")\n",
    "    print(f\"   PEFT: {peft.__version__}\")\n",
    "    print(\"\\nüéâ ¬°Todo listo para hacer fine-tuning!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error en la verificaci√≥n: {e}\")\n",
    "    print(\"Puede que necesites reiniciar el kernel del notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: loralib, torchdata\u001b[0m\u001b[33m\n",
      "\u001b[0mName: torch\n",
      "Version: 2.8.0+cpu\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: accelerate, peft, torchaudio, torchvision\n",
      "---\n",
      "Name: transformers\n",
      "Version: 4.56.1\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: peft\n",
      "---\n",
      "Name: datasets\n",
      "Version: 4.0.0\n",
      "Summary: HuggingFace community-driven open-source library of datasets\n",
      "Home-page: https://github.com/huggingface/datasets\n",
      "Author: HuggingFace Inc.\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache 2.0\n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyyaml, requests, tqdm, xxhash\n",
      "Required-by: evaluate\n",
      "---\n",
      "Name: evaluate\n",
      "Version: 0.4.5\n",
      "Summary: HuggingFace community-driven open-source library of evaluation\n",
      "Home-page: https://github.com/huggingface/evaluate\n",
      "Author: HuggingFace Inc.\n",
      "Author-email: leandro@huggingface.co\n",
      "License: Apache 2.0\n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: datasets, dill, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, requests, tqdm, xxhash\n",
      "Required-by: \n",
      "---\n",
      "Name: rouge-score\n",
      "Version: 0.1.2\n",
      "Summary: Pure python implementation of ROUGE-1.5.5.\n",
      "Home-page: https://github.com/google-research/google-research/tree/master/rouge\n",
      "Author: Google LLC\n",
      "Author-email: rouge-opensource@google.com\n",
      "License: \n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: absl-py, nltk, numpy, six\n",
      "Required-by: \n",
      "---\n",
      "Name: peft\n",
      "Version: 0.17.1\n",
      "Summary: Parameter-Efficient Fine-Tuning (PEFT)\n",
      "Home-page: https://github.com/huggingface/peft\n",
      "Author: The HuggingFace team\n",
      "Author-email: benjamin@huggingface.co\n",
      "License: Apache\n",
      "Location: /home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages\n",
      "Requires: accelerate, huggingface_hub, numpy, packaging, psutil, pyyaml, safetensors, torch, tqdm, transformers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show torch torchdata transformers datasets evaluate rouge_score loralib peft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GV0mclXEV7aV"
   },
   "source": [
    "<a name='1.1'></a>\n",
    "### 1.1 - Set up Kernel and Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pFVij_p3V7aX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importe los componentes necesarios.\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
    "import torch\n",
    "import time\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtIOTMkrV7aX",
    "tags": []
   },
   "source": [
    "<a name='1.2'></a>\n",
    "### 1.2 - Cargar Dataset y LLM\n",
    "\n",
    "[Finance-Instruct-500k](https://huggingface.co/datasets/Josephgflowers/Finance-Instruct-500k) es un dataset de Hugging Face especializado en instrucciones financieras. Contiene m√°s de 500,000 ejemplos de instrucciones financieras con sus respectivas respuestas, perfecto para fine-tuning con LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "52e88adfc6324f06a2957699938e349f",
      "1c727073a23e4c29a685221fc2c8297d",
      "20e73a01ed92416f9111b87ea630c1ec",
      "d137e6f6e7d14bd68b13c9ffff7444b6",
      "8e35b400ff644bd4af0079392a461000",
      "7af87c4f3c0f4ad7ad90c5b835743f8c",
      "",
      "848d8e40c254442b8cc93c64c7176dcd"
     ]
    },
    "id": "hmH9Or7RV7aY",
    "outputId": "610d1c04-7334-4417-d894-75b0c3828f0a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Josephgflowers/Finance-Instruct-500k\", split=\"train[:10000]\")  # Solo primeros 10K ejemplos\n",
    "\n",
    "# Convertir a DatasetDict si necesitas splits\n",
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict({\"train\": dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system': Value('string'), 'user': Value('string'), 'assistant': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"].features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBsjjW4OV7aY",
    "tags": []
   },
   "source": [
    "Cargamos el modelo pre-entrenado [T5-small](https://huggingface.co/t5-small) y su tokenizador directamente desde HuggingFace. T5-small es una versi√≥n m√°s liviana con solo 60M par√°metros, ideal para fine-tuning r√°pido con LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "681aacbb846341d68528367bf1e6ea5e",
      "4e0a9c5d95cb4edf87322c51dc4b6ad7",
      "055404322df7485a9276138114ecb109",
      "5200456208324ff5b5daafd329e11a67",
      "e8fe83c03ef94d50a02233c5c4776e14",
      "ab65d51105de4aac840a2f3a27291ffb",
      "2e0dbf02a6fc4deab0e7b59375fcd9a2"
     ]
    },
    "id": "SsEMZw1CV7aY",
    "outputId": "89265c6d-4e74-486e-8c76-c73a7a9a174a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargamos el modelo y el tokenizador\n",
    "\n",
    "model_name='google/flan-t5-small'\n",
    "# model_name='t5-google/flan-t5-small'\n",
    "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir7FTf20V7aY",
    "tags": []
   },
   "source": [
    "Es posible extraer la cantidad de par√°metros del modelo y descubrir cu√°ntos de ellos se pueden entrenar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dYnW_pqiV7aY",
    "outputId": "0eae56e9-4dd9-4cfe-97fc-4233f73c04fd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros entrenables del modelo: 76,961,152\n",
      " Total de parametros del modelo: 76,961,152\n",
      " Porcentaje de parametros entrenables 100%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"Parametros entrenables del modelo: {trainable_model_params:,.0f}\\n Total de parametros del modelo: {all_model_params:,.0f}\\n Porcentaje de parametros entrenables {100 * trainable_model_params / all_model_params:.0f}%\"\n",
    "#print(f'El area es: {area:,.2f}')\n",
    "print(print_number_of_trainable_model_parameters(original_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Explorando el dataset Finance-Instruct-500k...\n",
      "Splits disponibles: ['train']\n",
      "Tipo de dataset: <class 'datasets.dataset_dict.DatasetDict'>\n",
      "\n",
      "üìä Split 'train':\n",
      "   - Cantidad de ejemplos: 10000\n",
      "   - Columnas: ['system', 'user', 'assistant']\n",
      "\n",
      "üìù Ejemplo del split 'train':\n",
      "   - user: Explain tradeoffs between fiscal and monetary policy as tools in a nation's economic toolkit. Provid...\n",
      "   - assistant: Fiscal and monetary policy are the two main tools that governments have to influence economic activi...\n"
     ]
    }
   ],
   "source": [
    "# Verificar la estructura del dataset Finance-Instruct-500k\n",
    "print(\"üîç Explorando el dataset Finance-Instruct-500k...\")\n",
    "print(f\"Splits disponibles: {list(dataset.keys())}\")\n",
    "print(f\"Tipo de dataset: {type(dataset)}\")\n",
    "\n",
    "# Ver informaci√≥n de cada split disponible\n",
    "for split_name in dataset.keys():\n",
    "    print(f\"\\nüìä Split '{split_name}':\")\n",
    "    print(f\"   - Cantidad de ejemplos: {len(dataset[split_name])}\")\n",
    "    print(f\"   - Columnas: {list(dataset[split_name].features.keys())}\")\n",
    "\n",
    "# Mostrar un ejemplo del primer split disponible\n",
    "first_split = list(dataset.keys())[0]\n",
    "print(f\"\\nüìù Ejemplo del split '{first_split}':\")\n",
    "print(f\"   - user: {dataset[first_split][0]['user'][:100]}...\")\n",
    "print(f\"   - assistant: {dataset[first_split][0]['assistant'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Creando divisiones manuales del dataset...\n",
      "El dataset solo tiene 'train'. Dividiendo manualmente...\n",
      "Total de ejemplos: 10,000\n",
      "üìä Divisi√≥n propuesta:\n",
      "   - Train: 0 a 7,000 (70%)\n",
      "   - Validation: 7,000 a 8,500 (15%)\n",
      "   - Test: 8,500 a 10,000 (15%)\n",
      "‚úÖ Dataset dividido exitosamente!\n",
      "   - Train: 7,000 ejemplos\n",
      "   - Validation: 1,500 ejemplos\n",
      "   - Test: 1,500 ejemplos\n"
     ]
    }
   ],
   "source": [
    "# Dividir manualmente el dataset si solo tiene 'train'\n",
    "print(\"üõ†Ô∏è Creando divisiones manuales del dataset...\")\n",
    "\n",
    "if len(dataset.keys()) == 1 and 'train' in dataset.keys():\n",
    "    print(\"El dataset solo tiene 'train'. Dividiendo manualmente...\")\n",
    "    \n",
    "    # Obtener el total de ejemplos\n",
    "    total_examples = len(dataset['train'])\n",
    "    print(f\"Total de ejemplos: {total_examples:,}\")\n",
    "    \n",
    "    # Definir √≠ndices para cada split (puedes ajustar estos porcentajes)\n",
    "    train_end = int(0.7 * total_examples)      # 70% para entrenamiento\n",
    "    val_end = int(0.85 * total_examples)       # 15% para validaci√≥n  \n",
    "    # El resto (15%) ser√° para test\n",
    "    \n",
    "    print(f\"üìä Divisi√≥n propuesta:\")\n",
    "    print(f\"   - Train: 0 a {train_end:,} ({70}%)\")\n",
    "    print(f\"   - Validation: {train_end:,} a {val_end:,} ({15}%)\")  \n",
    "    print(f\"   - Test: {val_end:,} a {total_examples:,} ({15}%)\")\n",
    "    \n",
    "    # Crear los nuevos splits manualmente\n",
    "    train_data = dataset['train'].select(range(0, train_end))\n",
    "    val_data = dataset['train'].select(range(train_end, val_end))\n",
    "    test_data = dataset['train'].select(range(val_end, total_examples))\n",
    "    \n",
    "    # Crear el nuevo diccionario de dataset\n",
    "    from datasets import DatasetDict\n",
    "    dataset = DatasetDict({\n",
    "        'train': train_data,\n",
    "        'validation': val_data,\n",
    "        'test': test_data\n",
    "    })\n",
    "    \n",
    "    print(\"‚úÖ Dataset dividido exitosamente!\")\n",
    "    print(f\"   - Train: {len(dataset['train']):,} ejemplos\")\n",
    "    print(f\"   - Validation: {len(dataset['validation']):,} ejemplos\")\n",
    "    print(f\"   - Test: {len(dataset['test']):,} ejemplos\")\n",
    "\n",
    "else:\n",
    "    print(\"El dataset ya tiene m√∫ltiples splits:\")\n",
    "    for split_name in dataset.keys():\n",
    "        print(f\"   - {split_name}: {len(dataset[split_name]):,} ejemplos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbNtotpbV7aZ",
    "tags": []
   },
   "source": [
    "<a name='1.3'></a>\n",
    "### 1.3 - Prueba del modelo con Zero Shot Inferencing\n",
    "\n",
    "Pruebe el modelo con la inferencia de tiro cero. Puede ver que el modelo tiene dificultades para resumir el di√°logo en comparaci√≥n con el resumen de referencia, pero extrae informaci√≥n importante del texto que indica que el modelo se puede ajustar a la tarea en cuesti√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ruNKVIGEV7aZ",
    "outputId": "25596b54-9780-47a5-83eb-80ec09e2d111",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      " PROMPT DE ENTRADA:\n",
      "\n",
      "financial instruction: As a math student with a background in applied mathematics and numerics, how can I transition into the field of mathematical finance without prior knowledge in finance or economics?\n",
      "\n",
      "Answer:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "RESPUESTA HUMANA (BASELINE) :\n",
      "To transition into mathematical finance without prior knowledge in the field, consider the following steps:\n",
      "\n",
      "* Acquire foundational knowledge: Begin by reading introductory books on finance and economics, such as \"Investment Science\" by Luenberger.\n",
      "* Study mathematical finance: Enroll in courses or read books on mathematical finance, such as \"Stochastic Calculus for Finance\" by Steven Shreve or \"Monte Carlo Methods in Financial Engineering\" by Glasserman.\n",
      "* Build a strong statistical foundation: Focus on mastering multivariate statistics and time series analysis.\n",
      "* Improve linear algebra skills: Advance your understanding of matrix analysis and functional analysis.\n",
      "* Explore related topics: Investigate areas where your existing knowledge intersects with finance, such as stochastic differential equations and random processes.\n",
      "* Consider attending relevant lectures: Identify and attend university lectures that cover topics in mathematical finance.\n",
      "* Learn financial software: Familiarize yourself with programming languages and software used in finance, such as R or Python.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "RESPUESTA GENERADA POR EL MODELO CON ZERO SHOT:\n",
      "a mathematical education\n"
     ]
    }
   ],
   "source": [
    "index = 200\n",
    "\n",
    "# Extraemos la instrucci√≥n y respuesta del nuevo dataset\n",
    "instruction = dataset['test'][index]['user']\n",
    "expected_response = dataset['test'][index]['assistant']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "financial instruction: {instruction}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    original_model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=200,\n",
    "    )[0],\n",
    "    skip_special_tokens=True \n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f' PROMPT DE ENTRADA:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'RESPUESTA HUMANA (BASELINE) :\\n{expected_response}\\n')\n",
    "print(dash_line)\n",
    "print(f'RESPUESTA GENERADA POR EL MODELO CON ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-zTt-k9V7aZ",
    "tags": []
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Realizar Full Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7EhKQABV7aZ",
    "tags": []
   },
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - Preprocesar el dataset Dialog-Summary\n",
    "\n",
    "Se necesita convertir los pares dialogo-resumen (prompt-response) en instrucciones expl√≠citas para el LLM. Agregar una instrucci√≥n al inicio del dialogo como `Summarize the following conversation` y al inicio del resumen agregar `Summary`como se muestra a continuaci√≥n:\n",
    "\n",
    "Training prompt (dialogue):\n",
    "```\n",
    "Summarize the following conversation.\n",
    "\n",
    "    Chris: This is his part of the conversation.\n",
    "    Antje: This is her part of the conversation.\n",
    "    \n",
    "Summary:\n",
    "```\n",
    "\n",
    "Training response (summary):\n",
    "```\n",
    "Both Chris and Antje participated in the conversation.\n",
    "```\n",
    "\n",
    "Then preprocess the prompt-response dataset into tokens and pull out their `input_ids` (1 per token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      ""
     ]
    },
    "id": "kQd6neWAV7aZ",
    "outputId": "1e2c96f5-4b37-472c-f239-d5a206cc8dab",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of prompt list:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1000/1500 [00:01<00:00, 677.48 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of prompt list:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [00:02<00:00, 664.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    # El dataset Finance-Instruct-500k tiene 'user' (instrucci√≥n) y 'assistant' (respuesta)\n",
    "    # Formato: \"Instrucci√≥n: <user>\\n\\nRespuesta: \"\n",
    "    start_prompt = 'Instrucci√≥n financiera: '\n",
    "    end_prompt = '\\n\\nRespuesta: '\n",
    "    \n",
    "    # Construimos el prompt para cada ejemplo en el batch\n",
    "    prompt = [start_prompt + instruction + end_prompt for instruction in example[\"user\"]]\n",
    "    print(\"Size of prompt list: \", len(prompt))  # Imprimir el tama√±o de la lista\n",
    "    \n",
    "    # Tokenizamos los prompts (inputs)\n",
    "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    # Tokenizamos las respuestas (labels)\n",
    "    example['labels'] = tokenizer(example[\"assistant\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    return example\n",
    "\n",
    "# El dataset Finance-Instruct-500k contiene 3 splits: train, validation, test\n",
    "# La funci√≥n tokenize_function procesa todos los datos en batches\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Removemos las columnas originales, manteniendo solo input_ids y labels\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['system', 'user', 'assistant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 1\n",
      "})\n",
      "Column([[29169, 11, 3, 14356, 1291, 33, 8, 192, 711, 1339, 24, 10524, 43, 12, 2860, 1456, 1756, 5, 328, 284, 43, 1393, 11, 3314, 1549, 7, 5, 29169, 1291, 2401, 7, 12, 789, 2887, 11, 1104, 257, 3055, 5, 19119, 13, 5043, 1291, 560, 10, 1697, 3, 2092, 8, 1651, 419, 19988, 6, 8, 412, 5, 134, 5, 789, 6960, 3, 9, 5043, 26544, 190, 8, 797, 16532, 11, 419, 15601, 297, 1983, 13, 10425, 100, 1285, 1936, 2887, 30, 3620, 6, 1104, 8620, 6, 11, 8148, 17646, 1393, 5, 37, 8762, 47, 12, 4888, 12955, 2173, 11, 14954, 1456, 1756, 5, 6536, 43, 435, 24, 8, 26544, 141, 3, 9, 1465, 68, 11306, 1113, 30, 1456, 1170, 5, 1697, 37, 2523, 3602, 6960, 1104, 8620, 16, 1233, 28, 8, 1288, 13, 3094, 268, 1729, 11, 1170, 5, 611, 6, 8, 1504, 30, 1170, 65, 118, 5054, 26, 6, 11, 8, 1104, 8620, 4019, 1936, 8, 2822, 1487, 11724, 5, 1290, 1582, 1208, 1291, 2401, 7, 12, 3055, 57, 3, 9, 2069, 2137, 6, 114, 8, 5034, 9473, 6, 81, 1046, 1917, 11, 8, 540, 1899, 5, 19119, 13, 3, 14356, 1291, 560, 10, 1697, 621, 8, 2628, 981, 5362, 6, 8, 10803, 3, 22055, 1046, 1917, 12, 1084, 5733, 11, 6960, 18906, 3, 16927, 1356, 12, 993, 27605, 5, 37, 8762, 47, 12, 4888, 16391, 6, 1729, 6, 11, 3733, 2887, 5, 506, 2874, 33, 3, 16473, 28, 2022, 8, 2717, 8303, 5, 1697, 86, 8, 1480, 5541, 7, 6, 8, 10803, 3279, 1046, 1917, 12, 1428, 12485, 1208, 1666, 7, 45, 1456, 1170, 5, 16808, 1917, 9859, 12, 2684, 53, 8, 2717, 11, 3, 16217, 3, 9, 22440, 16, 1596, 5, 37, 843, 1668, 1647, 7, 33, 10, 1697, 29169, 1291, 54, 43, 3, 9, 72, 7774, 1113, 68, 1217, 1200, 12, 4028, 788, 12, 8, 1827, 433, 5, 1290, 1582, 1208, 1291, 19, 72, 3, 29, 603, 2296, 68, 65, 3, 9, 3, 13627, 2860, 30, 8, 2717, 5, 1697, 29169, 1291, 11737, 8, 1487, 11724, 6, 298, 3, 14356, 1291, 405, 59, 1461, 2603, 789, 2814, 5, 611, 6, 182, 731, 1046, 1917, 788, 12, 3, 14356, 1291, 54, 2454, 1146, 789, 24564, 5, 1697, 1290, 1582, 1208, 1291, 2134, 7, 12, 36, 705, 22937, 738, 2936, 6, 298, 5043, 1291, 12152, 557, 522, 72, 8263, 5, 86, 9251, 6, 321, 1339, 43, 7796, 11, 6900, 11, 161, 200, 16, 26947, 12, 21323, 8, 2717, 11, 11072, 1170, 5, 37, 6624, 2153, 5619, 30, 8, 806, 1456, 1124, 11, 1291, 1766, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print (type(tokenized_datasets))\n",
    "first_example = tokenized_datasets[\"train\"].select([0])\n",
    "print(first_example)\n",
    "print(first_example['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8HypBOxV7aa",
    "tags": []
   },
   "source": [
    "Para ahorrar algo de tiempo en el laboratorio, submuestrear√° el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      ""
     ]
    },
    "id": "S2qI0XRXV7aa",
    "outputId": "ee9215a9-f571-4405-d443-0850ec92439d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter:   0%|          | 0/1500 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1500/1500 [00:01<00:00, 1101.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 100 == 0, with_indices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcZHpjXiV7aa",
    "tags": []
   },
   "source": [
    "Compruebe las formas de las tres partes del conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Zzg-w16UV7aa",
    "outputId": "3f2b7e80-d13a-43cc-d90a-54ec85528478",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the datasets:\n",
      "Training: (70, 2)\n",
      "Validation: (15, 2)\n",
      "Test: (15, 2)\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 70\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 15\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'labels'],\n",
      "        num_rows: 15\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of the datasets:\")\n",
    "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
    "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
    "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
    "\n",
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4sYS5pDV7aa"
   },
   "source": [
    "El dataset de salida esta listo para el fine-tunning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aBoXNXzV7ap"
   },
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Fine tunning Eficiente de Par√°metros (PEFT)\n",
    "\n",
    "Ahora, realicemos un ajuste fino **PEFT** en lugar del ajuste fino completo, como se hizo anteriormente. PEFT es una forma de ajuste fino de instrucciones mucho m√°s eficiente que el ajuste fino completo, con resultados de evaluaci√≥n comparables, como ver√° pronto.\n",
    "\n",
    "PEFT es un t√©rmino gen√©rico que incluye **Adaptaci√≥n de Bajo Rango (LoRA)** y ajuste de prompts (¬°que NO ES LO MISMO que ingenier√≠a de prompts!). En la mayor√≠a de los casos, cuando alguien habla de PEFT, se refiere a LoRA. LoRA, a un nivel muy alto, permite al usuario ajustar su modelo utilizando menos recursos computacionales (en algunos casos, una sola GPU). Despu√©s del ajuste fino para una tarea, caso de uso o inquilino espec√≠fico con LoRA, el resultado es que el LLM original permanece sin cambios y surge un nuevo \"adaptador LoRA\". Este adaptador LoRA es mucho m√°s peque√±o que el LLM original: aproximadamente un porcentaje de un solo d√≠gito del tama√±o del LLM original (MB vs. GB).\n",
    "\n",
    "No obstante, en el momento de la inferencia, el adaptador LoRA debe reunirse y combinarse con su LLM original para atender la solicitud de inferencia. La ventaja, sin embargo, es que muchos adaptadores LoRA pueden reutilizar el LLM original, lo que reduce los requisitos generales de memoria al atender m√∫ltiples tareas y casos de uso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9hjS-tsV7ap"
   },
   "source": [
    "<a name='3.1'></a>\n",
    "\n",
    "\n",
    "### 3.1 - Configuraci√≥n del modelo PEFT/LoRA para el ajuste fino\n",
    "\n",
    "Debe configurar el modelo PEFT/LoRA para el ajuste fino con un nuevo adaptador de capa/par√°metro. Al usar PEFT/LoRA, se congela el LLM subyacente y solo se entrena el adaptador. Observe la configuraci√≥n de LoRA a continuaci√≥n. Observe el hiperpar√°metro de rango (`r`), que define el rango/dimensi√≥n del adaptador que se va a entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "iOjoDSwWV7ap",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32, # Rank\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMIM04QQV7ap",
    "tags": []
   },
   "source": [
    "Add LoRA adapter layers/parameters to the original LLM to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "LnFsAZn-V7aq",
    "outputId": "f51c1974-cbb5-41ab-9fc9-33c458a7f804",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros entrenables del modelo: 1,376,256\n",
      " Total de parametros del modelo: 78,337,408\n",
      " Porcentaje de parametros entrenables 2%\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(original_model,\n",
    "                            lora_config)\n",
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_ONKxTAV7aq",
    "tags": []
   },
   "source": [
    "<a name='3.2'></a>\n",
    "### 3.2 - Train PEFT Adapter\n",
    "\n",
    "Define training arguments and create `Trainer` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CN-Dbz23V7aq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = f'./peft-finance-instruct-training-{str(int(time.time()))}'\n",
    "\n",
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    auto_find_batch_size=True,\n",
    "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=1,\n",
    "    max_steps=5\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHBCtG41V7aq"
   },
   "source": [
    "Now everything is ready to train the PEFT adapter and save the model.\n",
    "\n",
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DpmZQBsMV7aq",
    "outputId": "190e13b1-4dfe-4fd6-ea51-5da0c34eaf98",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/Desktop/IA2/mi_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 1:09:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>15.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('./peft-dialogue-summary-checkpoint-local/tokenizer_config.json',\n",
       " './peft-dialogue-summary-checkpoint-local/special_tokens_map.json',\n",
       " './peft-dialogue-summary-checkpoint-local/spiece.model',\n",
       " './peft-dialogue-summary-checkpoint-local/added_tokens.json',\n",
       " './peft-dialogue-summary-checkpoint-local/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.train()\n",
    "peft_model_path=\"./peft-dialogue-summary-checkpoint-local\"\n",
    "peft_trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3voqLpwV7aq",
    "tags": []
   },
   "source": [
    "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "886lESmdV7ar",
    "tags": []
   },
   "source": [
    "Prepare este modelo a√±adiendo un adaptador al modelo FLAN-T5 original. Est√° configurando `is_trainable=False` porque el plan es realizar inferencia √∫nicamente con este modelo PEFT. Si estuviera preparando el modelo para entrenamiento posterior, deber√≠a configurar `is_trainable=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5FCVCdu8V7ar",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\", torch_dtype=torch.bfloat16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
    "                                       './peft-dialogue-summary-checkpoint-local/',\n",
    "                                       torch_dtype=torch.bfloat16,\n",
    "                                       is_trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uretNB0sV7ar",
    "tags": []
   },
   "source": [
    "The number of trainable parameters will be `0` due to `is_trainable=False` setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HqWoJBCrV7ar",
    "outputId": "0377ef7e-bd4a-42af-d559-788b9c4b6b89",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros entrenables del modelo: 0\n",
      " Total de parametros del modelo: 78,337,408\n",
      " Porcentaje de parametros entrenables 0%\n"
     ]
    }
   ],
   "source": [
    "print(print_number_of_trainable_model_parameters(peft_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywXzSfTrV7ar"
   },
   "source": [
    "<a name='3.3'></a>\n",
    "### 3.3 - Evaluate the Model Qualitatively (Human Evaluation)\n",
    "\n",
    "Make inferences for the same example as in sections [1.3](#1.3) and [2.3](#2.3), with the original model, fully fine-tuned and PEFT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Cpcpbtj1V7as",
    "outputId": "ffd18e06-ab2c-438e-86bd-4b27af6644e8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "INSTRUCCI√ìN FINANCIERA:\n",
      "As a math student with a background in applied mathematics and numerics, how can I transition into the field of mathematical finance without prior knowledge in finance or economics?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RESPUESTA HUMANA (BASELINE):\n",
      "To transition into mathematical finance without prior knowledge in the field, consider the following steps:\n",
      "\n",
      "* Acquire foundational knowledge: Begin by reading introductory books on finance and economics, such as \"Investment Science\" by Luenberger.\n",
      "* Study mathematical finance: Enroll in courses or read books on mathematical finance, such as \"Stochastic Calculus for Finance\" by Steven Shreve or \"Monte Carlo Methods in Financial Engineering\" by Glasserman.\n",
      "* Build a strong statistical foundation: Focus on mastering multivariate statistics and time series analysis.\n",
      "* Improve linear algebra skills: Advance your understanding of matrix analysis and functional analysis.\n",
      "* Explore related topics: Investigate areas where your existing knowledge intersects with finance, such as stochastic differential equations and random processes.\n",
      "* Consider attending relevant lectures: Identify and attend university lectures that cover topics in mathematical finance.\n",
      "* Learn financial software: Familiarize yourself with programming languages and software used in finance, such as R or Python.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MODELO ORIGINAL (google/flan-t5-small):\n",
      "Financial instruction: As a math student with a background in applied mathematics and numerics,\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MODELO PEFT (google/flan-t5-small + LoRA):\n",
      "a financial education\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dash_line = '-' * 100\n",
    "\n",
    "# Seleccionar un ejemplo del dataset\n",
    "index = 200\n",
    "instruction = dataset['test'][index]['user']\n",
    "expected_response = dataset['test'][index]['assistant']\n",
    "\n",
    "# Como no tienes instruct_model, compararemos solo original vs PEFT\n",
    "# El formato correcto para Finance-Instruct es diferente al de di√°logos\n",
    "prompt = f\"\"\"\n",
    "Financial instruction: {instruction}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generar respuestas\n",
    "original_model_outputs = original_model.generate(\n",
    "    input_ids=input_ids, \n",
    "    generation_config=GenerationConfig(max_new_tokens=200, num_beams=1)\n",
    ")\n",
    "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "peft_model_outputs = peft_model.generate(\n",
    "    input_ids=input_ids, \n",
    "    generation_config=GenerationConfig(max_new_tokens=200, num_beams=1)\n",
    ")\n",
    "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Mostrar comparaci√≥n\n",
    "print(dash_line)\n",
    "print(f'INSTRUCCI√ìN FINANCIERA:\\n{instruction}')\n",
    "print(dash_line)\n",
    "print(f'RESPUESTA HUMANA (BASELINE):\\n{expected_response}')\n",
    "print(dash_line)\n",
    "print(f'MODELO ORIGINAL (google/flan-t5-small):\\n{original_model_text_output}')\n",
    "print(dash_line)\n",
    "print(f'MODELO PEFT (google/flan-t5-small + LoRA):\\n{peft_model_text_output}')\n",
    "print(dash_line)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "mi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
